{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddata(a, b):\n",
    "    import h5py\n",
    "    with h5py.File(a+'.h5','r') as H:\n",
    "        data = np.copy(H['data'])\n",
    "    with h5py.File(b+'.h5','r') as H:\n",
    "        label = np.copy(H['label'])\n",
    "\n",
    "    X = np.reshape(data,(data.shape[0],-1))\n",
    "    X=X.T\n",
    "    Y=np.reshape(label, (label.shape[0],1))\n",
    "    X=X/255\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Validation with 20% data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Validation_dataset(X, Y, percent):\n",
    "    k=int((percent/100)*X.shape[1])\n",
    "    rand= np.random.permutation(X.shape[1])\n",
    "    rand= rand[0:k]\n",
    "    All_index=np.arange(X.shape[1])\n",
    "    a=set(rand)\n",
    "    b=set(All_index)\n",
    "    c=b-a\n",
    "    a=sorted(a)\n",
    "    c=sorted(c)\n",
    "\n",
    "    Train_Data_mat=np.zeros((X.shape[0],len(c)))\n",
    "    Train_labels= np.zeros((len(c)))\n",
    "    Val_Data_mat=np.zeros((X.shape[0], len(a)))\n",
    "    Val_labels= np.zeros((len(a)))\n",
    "    for i in range(len(c)):\n",
    "        Train_Data_mat[:,i]=X[:,c[i]]\n",
    "        Train_labels[i]= Y[c[i]]\n",
    "    for i in range(len(a)):\n",
    "        Val_Data_mat[:,i]=X[:,a[i]]\n",
    "        Val_labels[i]= Y[a[i]] \n",
    "        \n",
    "    return Train_Data_mat, Train_labels, Val_Data_mat, Val_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data Preprocessing:  Normalisation & SVD for rank reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVD(X, var_desired):\n",
    "    U, s, Vt= np.linalg.svd(X, full_matrices=False)\n",
    "    sum_ev_sq=np.sum(s**2)\n",
    "    s_square=np.square(s)\n",
    "    cumsum_s=np.cumsum(s_square)\n",
    "    var_arr=cumsum_s/sum_ev_sq\n",
    "    k=np.argmax(var_arr>var_desired)\n",
    "    k=k+1\n",
    "    S=np.diag(s)\n",
    "    X_hat_reconst=U[:,0:k].dot(S[0:k,0:k]).dot(Vt[0:k,:])\n",
    "    n=k\n",
    "    comp_ratio = (X.shape[1]*n + n + X.shape[0]*n)/(X.shape[1] * X.shape[0])\n",
    "    return X_hat_reconst, k, comp_ratio      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Logistic Regression Classifier using Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary Logisitic Regression classifier\n",
    "def binry_classifier(X, Y, iterations, Eta, lamda):\n",
    "    import time\n",
    "    row_all_one=np.ones((1,len(X.T)))     #adding a row of all one\n",
    "    X=np.concatenate((row_all_one, X), 0)\n",
    "    Wk=np.zeros(len(X))\n",
    "    Wk1=Wk\n",
    "    for j in range(iterations):\n",
    "        labels_pred=[]\n",
    "        Wk=Wk1\n",
    "        for i in range(len(X.T)):\n",
    "            exp_part=np.dot((X[:,i]), Wk)\n",
    "            exp_part=-1*exp_part\n",
    "            exp_part=np.exp(exp_part)\n",
    "            if(exp_part<=1):\n",
    "                labels_pred.append(1)\n",
    "            else:\n",
    "                labels_pred.append(0)\n",
    "        labels_pred=np.asarray(labels_pred)\n",
    "        Comp_Grad_1=np.sum(X*labels_pred, axis=1)\n",
    "        Comp_Grad_2=np.sum(X*Y, axis=1)\n",
    "        Grad=Comp_Grad_1-Comp_Grad_2\n",
    "        Grad=Grad/len(X.T) \n",
    "        Grad=Grad+ lamda*Wk\n",
    "        Wk1= Wk1 - Eta*Grad\n",
    "        if(abs((np.linalg.norm(Wk)-np.linalg.norm(Wk1)))<1e-12):   #convergence\n",
    "            diff=abs(np.linalg.norm(Wk)-np.linalg.norm(Wk1))\n",
    "            print(\"The value of norm is\", diff)\n",
    "            break\n",
    "    diff=np.linalg.norm(Wk)-np.linalg.norm(Wk1)\n",
    "    return Wk1, labels_pred      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Confusn_mat(labels_pred, Y):\n",
    "    lst=[]\n",
    "    true_pos=0\n",
    "    false_posit=0\n",
    "    false_negat=0\n",
    "    true_neg=0\n",
    "    for i in range(len(labels_pred)):\n",
    "        if (labels_pred[i]== 1 and Y[i]==1):\n",
    "            true_pos=true_pos +1\n",
    "        elif (labels_pred[i]==1 and Y[i]==0):\n",
    "            false_posit=false_posit+1\n",
    "        elif (labels_pred[i]==0 and Y[i]==1):\n",
    "            false_negat=false_negat+1\n",
    "        else:\n",
    "            true_neg=true_neg+1\n",
    "    lst=[true_pos, false_posit, false_negat, true_neg]\n",
    "    lst=np.asarray(lst)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "def Parameters(true_pos, false_posit, false_negat, true_neg, which_data_dataset):\n",
    "    if(which_data_dataset == \"testing\" or which_data_dataset ==\"validation\" or which_data_dataset == \"training_data\"):\n",
    "        print(true_pos, false_posit, false_negat, true_neg)\n",
    "    lst=[]\n",
    "    Accuracy=((true_pos+true_neg)/(true_pos+true_neg+false_posit+false_negat))*100\n",
    "    Accuracy = (np.round(Accuracy,2))/100\n",
    "    Precision= true_pos/(true_pos+false_posit) \n",
    "    Precision = np.round(Precision,2)\n",
    "    Recall= true_pos/(true_pos+false_negat)\n",
    "    Recall = np.round(Recall,2)\n",
    "    F_measure=(2*true_pos)/(2*true_pos + false_negat+ false_posit)\n",
    "    F_measure = np.round(F_measure,2)\n",
    "    TPR=true_pos/(true_pos + false_negat)\n",
    "    TPR = np.round(TPR,2)\n",
    "    FPR= false_posit/(false_posit + true_neg)\n",
    "    FPR = np.round(FPR,2)\n",
    "    lst=[Accuracy, Precision, Recall, F_measure, TPR, FPR]\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning One Vs All implementation\n",
    "def one_vs_All_train(X, Y):\n",
    "    unique, counts=np.unique(Y, return_counts=True)\n",
    "    opt_W=np.zeros((len(unique), X.shape[0]+1))\n",
    "    labels_pred=np.zeros((len(unique), len(Y)))\n",
    "    for j in range(len(unique)):\n",
    "        Y_bin=np.zeros(len(Y))\n",
    "        lst=[]\n",
    "        for i in range(len(Y)):\n",
    "            if (Y[i]==j):\n",
    "                Y_bin[i]=1\n",
    "            else:\n",
    "                Y_bin[i]=0\n",
    "        opt_W[j], labels_pred[j] =binry_classifier(X, Y_bin, 200, 1e-5, np.exp(-50))\n",
    "        lst=Confusn_mat(labels_pred[j], Y_bin)\n",
    "    return opt_W, labels_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Training the Classifier One Vs All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SVD has number of components as 89 with compression ratio of 0.11723347151360544\n",
      "Running time: 38 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "X, Y=loaddata(\"images_training\", \"labels_training\")\n",
    "variance=0.96\n",
    "sample_times=3\n",
    "unique, counts=np.unique(Y, return_counts=True)\n",
    "opt_W_Avg=np.zeros((len(unique), X.shape[0]+1))\n",
    "for i in range(sample_times):\n",
    "    X_post_Val_data, Y_post_Val_labels, Val_Data, Val_labels=Validation_dataset(X, Y, 20)\n",
    "    X_post_Val_data, n_components, comp_ratio = SVD(X_post_Val_data,variance)\n",
    "    opt_W, labels_pred = one_vs_All_train(X_post_Val_data, Y_post_Val_labels)\n",
    "    opt_W_Avg= opt_W_Avg+ opt_W\n",
    "opt_W_Avg=opt_W_Avg/sample_times\n",
    "print(\"The SVD has number of components as {} with compression ratio of {}\".format(n_components,comp_ratio) )\n",
    "print(\"Running time: \"+ str(int((time.time()-start_time)/60))+\" minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Testing Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_All(X, W):\n",
    "    row_all_one=np.ones((1,len(X.T)))\n",
    "    X=np.concatenate((row_all_one, X), 0)\n",
    "    probabilities=np.dot(W, X)\n",
    "    pred_labels=np.argmax(probabilities, axis=0)\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindConfMat(pred_labels, Y_test, which_data_set):\n",
    "    unique, counts=np.unique(Y_test, return_counts=True)\n",
    "    Conf_mat4All= np.zeros((len(unique), 4))\n",
    "    Param_mat4All= np.zeros((len(unique), 6))\n",
    "    for j in range(len(unique)):\n",
    "        pred_labels_bin=[]\n",
    "        Y_test_bin=[]\n",
    "        for i in range(len(Y_test)):\n",
    "            if (pred_labels[i]==j):\n",
    "                pred_labels_bin.append(1)\n",
    "            else:\n",
    "                pred_labels_bin.append(0)\n",
    "            if(Y_test[i]==j):\n",
    "                Y_test_bin.append(1)\n",
    "            else:\n",
    "                Y_test_bin.append(0)\n",
    "        Conf_mat4All[j]=Confusn_mat(pred_labels_bin, Y_test_bin)\n",
    "        Param_mat4All[j]=Parameters(Conf_mat4All[j][0], Conf_mat4All[j][1], Conf_mat4All[j][2], Conf_mat4All[j][3], which_data_set)\n",
    "    return Conf_mat4All, Param_mat4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 76.11250000000001 %\n",
      "The confusion matrix for Training data for all classes showing TP, FP, FN, TN respectively:\n",
      "1864.0 652.0 514.0 20970.0\n",
      "2259.0 131.0 121.0 21489.0\n",
      "1000.0 160.0 1449.0 21391.0\n",
      "2275.0 2250.0 121.0 19354.0\n",
      "1509.0 641.0 902.0 20948.0\n",
      "2095.0 109.0 329.0 21467.0\n",
      "561.0 80.0 1808.0 21551.0\n",
      "2147.0 396.0 170.0 21287.0\n",
      "2283.0 1135.0 106.0 20476.0\n",
      "2274.0 179.0 213.0 21334.0\n",
      "The Performance matrix for all the classes involving Accuracy, Precision, Recall, F-measure, TPR and FPR:\n",
      "95.14 0.74 0.78 0.76 0.78 0.03\n",
      "98.95 0.95 0.95 0.95 0.95 0.01\n",
      "93.3 0.86 0.41 0.55 0.41 0.01\n",
      "90.12 0.5 0.95 0.66 0.95 0.1\n",
      "93.57 0.7 0.63 0.66 0.63 0.03\n",
      "98.18 0.95 0.86 0.91 0.86 0.01\n",
      "92.13 0.88 0.24 0.37 0.24 0.0\n",
      "97.64 0.84 0.93 0.88 0.93 0.02\n",
      "94.83 0.67 0.96 0.79 0.96 0.05\n",
      "98.37 0.93 0.91 0.92 0.91 0.01\n"
     ]
    }
   ],
   "source": [
    "#Testing over Training Data\n",
    "pred_labels = testing_All(X_post_Val_data, opt_W_Avg)\n",
    "acc=0\n",
    "for i in range(len(Y_post_Val_labels)):\n",
    "    if(Y_post_Val_labels[i]==pred_labels[i]):\n",
    "        acc=acc+1\n",
    "print(\"The accuracy is {} %\".format((acc/(len(Y_post_Val_labels)))*100))\n",
    "print(\"The confusion matrix for Training data for all classes showing TP, FP, FN, TN respectively:\")\n",
    "Conf_mat4All_train, Param_mat4All_train= FindConfMat(pred_labels, Y_post_Val_labels, \"training_data\")\n",
    "print (\"The Performance matrix for all the classes involving Accuracy, Precision, Recall, F-measure, TPR and FPR:\")\n",
    "for j in range (len(Param_mat4All_train)):\n",
    "    print(Param_mat4All_train[j][0]*100, Param_mat4All_train[j][1],Param_mat4All_train[j][2],Param_mat4All_train[j][3],Param_mat4All_train[j][4],Param_mat4All_train[j][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 75.73333333333333 %\n",
      "The confusion matrix for Validation data for all classes showing TP, FP, FN, TN respectively:\n",
      "487.0 171.0 146.0 5196.0\n",
      "532.0 41.0 44.0 5383.0\n",
      "239.0 49.0 332.0 5380.0\n",
      "577.0 604.0 29.0 4790.0\n",
      "370.0 135.0 248.0 5247.0\n",
      "533.0 41.0 71.0 5355.0\n",
      "142.0 24.0 456.0 5378.0\n",
      "534.0 85.0 44.0 5337.0\n",
      "584.0 268.0 29.0 5119.0\n",
      "546.0 38.0 57.0 5359.0\n",
      "The Performance matrix for all the classes involving Accuracy, Precision, Recall, F-measure, TPR and FPR:\n",
      "95.14 0.74 0.78 0.76 0.78 0.03\n",
      "98.95 0.95 0.95 0.95 0.95 0.01\n",
      "93.3 0.86 0.41 0.55 0.41 0.01\n",
      "90.12 0.5 0.95 0.66 0.95 0.1\n",
      "93.57 0.7 0.63 0.66 0.63 0.03\n",
      "98.18 0.95 0.86 0.91 0.86 0.01\n",
      "92.13 0.88 0.24 0.37 0.24 0.0\n",
      "97.64 0.84 0.93 0.88 0.93 0.02\n",
      "94.83 0.67 0.96 0.79 0.96 0.05\n",
      "98.37 0.93 0.91 0.92 0.91 0.01\n"
     ]
    }
   ],
   "source": [
    "#Testing over Validation Data\n",
    "pred_labels = testing_All(Val_Data, opt_W_Avg)\n",
    "acc=0\n",
    "for i in range(len(Val_labels)):\n",
    "    if(Val_labels[i]==pred_labels[i]):\n",
    "        acc=acc+1\n",
    "print(\"The accuracy is {} %\".format((acc/(len(Val_labels)))*100))\n",
    "print(\"The confusion matrix for Validation data for all classes showing TP, FP, FN, TN respectively:\")\n",
    "Conf_mat4All_valid, Param_mat4All_valid= FindConfMat(pred_labels, Val_labels, \"validation\")\n",
    "print (\"The Performance matrix for all the classes involving Accuracy, Precision, Recall, F-measure, TPR and FPR:\")\n",
    "for j in range (len(Param_mat4All_train)):\n",
    "    print(Param_mat4All_train[j][0]*100, Param_mat4All_train[j][1],Param_mat4All_train[j][2],Param_mat4All_train[j][3],Param_mat4All_train[j][4],Param_mat4All_train[j][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THe accuracy for test is 75.6 %\n",
      "The Confusion Matrix for Test data for all classes showing TP, FP, FN, TN respectively:\n",
      "136.0 50.0 42.0 1772.0\n",
      "181.0 9.0 10.0 1800.0\n",
      "86.0 20.0 124.0 1770.0\n",
      "185.0 191.0 6.0 1618.0\n",
      "129.0 64.0 83.0 1724.0\n",
      "177.0 6.0 37.0 1780.0\n",
      "46.0 7.0 154.0 1793.0\n",
      "188.0 27.0 10.0 1775.0\n",
      "208.0 91.0 11.0 1690.0\n",
      "176.0 23.0 11.0 1790.0\n",
      "The Performance matrix for all the classes involving Accuracy, Precision, Recall, F-measure, TPR and FPR:\n",
      "95.14 0.74 0.78 0.76 0.78 0.03\n",
      "98.95 0.95 0.95 0.95 0.95 0.01\n",
      "93.3 0.86 0.41 0.55 0.41 0.01\n",
      "90.12 0.5 0.95 0.66 0.95 0.1\n",
      "93.57 0.7 0.63 0.66 0.63 0.03\n",
      "98.18 0.95 0.86 0.91 0.86 0.01\n",
      "92.13 0.88 0.24 0.37 0.24 0.0\n",
      "97.64 0.84 0.93 0.88 0.93 0.02\n",
      "94.83 0.67 0.96 0.79 0.96 0.05\n",
      "98.37 0.93 0.91 0.92 0.91 0.01\n"
     ]
    }
   ],
   "source": [
    "# import testing data\n",
    "X_test, Y_test=loaddata(\"images_testing\", \"labels_testing_2000\")\n",
    "X_test, n_components_Test, comp_ratio_Test =SVD(X_test, variance)\n",
    "\n",
    "#Testing on 2000 Test Data\n",
    "pred_labels = testing_All(X_test, opt_W_Avg)\n",
    "acc=0\n",
    "for i in range(len(Y_test)):\n",
    "    if(Y_test[i]==pred_labels[i]):\n",
    "        acc=acc+1\n",
    "print(\"THe accuracy for test is {} %\".format((acc/(len(Y_test)))*100))\n",
    "print(\"The Confusion Matrix for Test data for all classes showing TP, FP, FN, TN respectively:\")\n",
    "Conf_mat4All_test, Param_mat4All_test= FindConfMat(pred_labels, Y_test, \"testing\")\n",
    "print (\"The Performance matrix for all the classes involving Accuracy, Precision, Recall, F-measure, TPR and FPR:\")\n",
    "for j in range (len(Param_mat4All_train)):\n",
    "    print(Param_mat4All_train[j][0]*100, Param_mat4All_train[j][1],Param_mat4All_train[j][2],Param_mat4All_train[j][3],Param_mat4All_train[j][4],Param_mat4All_train[j][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to output the data\n",
    "output=pred_labels\n",
    "import numpy as np \n",
    "import h5py\n",
    "with h5py.File('predicted_labels.h5','w') as H: \n",
    "    H.create_dataset('label',data=output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
